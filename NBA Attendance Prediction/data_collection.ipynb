{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f9210cd-452c-4cc9-a8ac-64b13eb137e0",
   "metadata": {},
   "source": [
    "<h1><center>NBA Game Attendance Prediction Main Data Collection</center></h1>\n",
    "\n",
    "This is a separate data collection notebook for the NBA Game Attendance Prediction project. This was done separately so that the large amount of data would only have to be collected once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186500f9-14af-4753-aa04-ca2404b3f63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#analytics stack\n",
    "import pandas as pd\n",
    "from pandasql import sqldf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import numpy as np\n",
    "import datetime \n",
    "import geopy.distance\n",
    "\n",
    "#nba_api package\n",
    "from nba_api.stats.static import players, teams\n",
    "from nba_api.stats.endpoints import leaguegamelog, boxscoresummaryv2\n",
    "\n",
    "#meteostat weather package\n",
    "from meteostat import Point, Daily, units"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c74dce-9565-466d-bf1e-3a6be651c287",
   "metadata": {},
   "source": [
    "### NBA Box Score and Attendance Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41167708-fb5d-43a6-b48e-3ffe41a8f3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions to change column names in game_data\n",
    "def col_home(df):\n",
    "    df.columns = [x + '_HOME' for x in df.columns]\n",
    "    return df\n",
    "\n",
    "def col_away(df):\n",
    "    df.columns = [x + '_AWAY' for x in df.columns]\n",
    "    return df\n",
    "\n",
    "#function to get and transform game data by season\n",
    "def game_data(seasons):\n",
    "    #get game data from nba api\n",
    "    games = leaguegamelog.LeagueGameLog(season=seasons, timeout = 100).get_data_frames()[0]\n",
    "    games['TEAM_ID'] = games['TEAM_ID'].astype(str)\n",
    "    \n",
    "    #store season_id, game_id and game_dates in separate lists\n",
    "    season_ids = games['SEASON_ID'].values[0]\n",
    "    game_ids = games['GAME_ID'].unique()\n",
    "    game_dates = [games['GAME_DATE'][i] for i in range(0,len(games),2)]\n",
    "    \n",
    "    #create new df to store revised structure\n",
    "    games_s = games.drop(['GAME_ID', 'SEASON_ID', 'GAME_DATE'], axis=1)\n",
    "    data = []\n",
    "    df = pd.DataFrame(data)\n",
    "    for i in range(0,len(games_s),2): #rename home and away columns in each row\n",
    "        if \"vs\" in games_s['MATCHUP'].values[i]:\n",
    "            home_team = col_home(games_s.iloc[[i]]).reset_index(drop = True)\n",
    "            away_team = col_away(games_s.iloc[[i+1]]).reset_index(drop = True)\n",
    "        else:\n",
    "            home_team = col_home(games_s.iloc[[i+1]]).reset_index(drop = True)\n",
    "            away_team = col_away(games_s.iloc[[i]]) .reset_index(drop = True)\n",
    "        df1 = pd.concat([home_team, away_team], axis=1) # combine the renamed rows into one\n",
    "        df = pd.concat([df, df1])\n",
    "    cols = list(df.columns.values)\n",
    "    cols = ['GAME_ID', 'SEASON_ID', 'GAME_DATE'] + cols\n",
    "    \n",
    "    #reassign game_id, season_id, game_date columns\n",
    "    df['GAME_ID'] = game_ids\n",
    "    df['SEASON_ID'] = season_ids\n",
    "    df['GAME_DATE'] = game_dates\n",
    "    df = df[cols]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7cba24a-dfe6-4b7f-b233-54a05ff4cf69",
   "metadata": {},
   "source": [
    "#### 2022-2023 Season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4fc927-7ba6-410b-a9d3-7da703c0587b",
   "metadata": {},
   "outputs": [],
   "source": [
    "games_2022 = game_data(2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd503382-3356-41ad-84c7-f6457b05f78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "missed_games = []\n",
    "attendance_dfs = []\n",
    "i = 1\n",
    "for game_id in games_2022['GAME_ID']:\n",
    "    try: \n",
    "        time.sleep(.75) #prevent connection time-out\n",
    "        b = boxscoresummaryv2.BoxScoreSummaryV2(game_id=game_id, timeout = 100).get_data_frames()[4]\n",
    "        b['GAME_ID'] = game_id\n",
    "        attendance_dfs.append(b)\n",
    "    except:\n",
    "        # track games that returned no response object\n",
    "        print(f'passed {i}, id: {game_id}')\n",
    "        missed_games.append(game_id)\n",
    "        i += 1\n",
    "        pass\n",
    "\n",
    "# check if missed games were due to timeout or faulty data\n",
    "print(f'DOING {len(missed_games)} MISSED GAMES')\n",
    "i=1\n",
    "missed_dfs = []\n",
    "for game_id in missed_games:\n",
    "    try: \n",
    "        time.sleep(.75) #prevent connection time-out\n",
    "        b = boxscoresummaryv2.BoxScoreSummaryV2(game_id=game_id, timeout = 100).get_data_frames()[4]\n",
    "        b['GAME_ID'] = game_id\n",
    "        missed_dfs.append(b)\n",
    "    except:\n",
    "        print(f'passed {i}, id: {game_id}')\n",
    "        missed_games.append(game_id)\n",
    "        i += 1\n",
    "        pass\n",
    "\n",
    "missed_games_2022 = pd.concat(missed_dfs)\n",
    "attendance_2022 = pd.concat(attendance_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69429785-4ea2-4ac4-990d-3ed491cafb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_2022 = pd.concat([attendance_2022, missed_games_2022])\n",
    "final_2022['GAME_DATE'] = pd.to_datetime(final_2022['GAME_DATE'])\n",
    "final_2022 = final_2022.sort_values('GAME_DATE')\n",
    "final_2022.to_csv('data/attendance_2022.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d80f41-4c3d-49a4-b723-d7b24c55da64",
   "metadata": {},
   "source": [
    "#### 2021-2022 Season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62353e6-aabf-4f51-a6fe-346acc29287c",
   "metadata": {},
   "outputs": [],
   "source": [
    "games_2021 = game_data(2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043b6904-5500-45f0-831d-b17afc4c035c",
   "metadata": {},
   "outputs": [],
   "source": [
    "missed_games = []\n",
    "attendance_dfs = []\n",
    "i = 1\n",
    "for game_id in games_2021['GAME_ID']:\n",
    "    try: \n",
    "        time.sleep(.75) #prevent connection time-out\n",
    "        b = boxscoresummaryv2.BoxScoreSummaryV2(game_id=game_id, timeout = 100).get_data_frames()[4]\n",
    "        b['GAME_ID'] = game_id\n",
    "        attendance_dfs.append(b)\n",
    "    except:\n",
    "        # track games that returned no response object\n",
    "        print(f'passed {i}, id: {game_id}')\n",
    "        missed_games.append(game_id)\n",
    "        i += 1\n",
    "        pass\n",
    "\n",
    "# check if missed games were due to timeout or faulty data\n",
    "print(f'DOING {len(missed_games)} MISSED GAMES')\n",
    "i=1\n",
    "missed_dfs = []\n",
    "for game_id in missed_games:\n",
    "    try: \n",
    "        time.sleep(.75) #prevent connection time-out\n",
    "        b = boxscoresummaryv2.BoxScoreSummaryV2(game_id=game_id, timeout = 100).get_data_frames()[4]\n",
    "        b['GAME_ID'] = game_id\n",
    "        missed_dfs.append(b)\n",
    "    except:\n",
    "        print(f'passed {i}, id: {game_id}')\n",
    "        missed_games.append(game_id)\n",
    "        i += 1\n",
    "        pass\n",
    "\n",
    "missed_games_2021 = pd.concat(missed_dfs)\n",
    "attendance_2021 = pd.concat(attendance_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7c87b3-2081-47e4-9442-18d1dca08034",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_2021 = pd.concat([attendance_2021, missed_games_2021])\n",
    "final_2021['GAME_DATE'] = pd.to_datetime(final_2021['GAME_DATE'])\n",
    "final_2021 = final_2021.sort_values('GAME_DATE')\n",
    "final_2021 = final_2021.merge(games_2021, how='left', on='GAME_ID')\n",
    "final_2021.to_csv('data/attendance_2021.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd4f73c-f48f-42ce-968e-6b8dcc0694c3",
   "metadata": {},
   "source": [
    "#### 2019-2020 Season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef47448-2223-455a-b87d-88fd41661dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "games_2019 = game_data(2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f1409d-3ae0-412f-83d9-6780f6223924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# account for Covid Bubble games with no attendance\n",
    "games_2019 = games_2019[games_2019['GAME_DATE'] < '2020-03-12']\n",
    "missed_games = []\n",
    "attendance_dfs = []\n",
    "\n",
    "i = 1\n",
    "for game_id in games_2019['GAME_ID']:\n",
    "    try: \n",
    "        time.sleep(.75) #prevent connection time-out\n",
    "        b = boxscoresummaryv2.BoxScoreSummaryV2(game_id=game_id, timeout = 100).get_data_frames()[4]\n",
    "        b['GAME_ID'] = game_id\n",
    "        attendance_dfs.append(b)\n",
    "    except:\n",
    "        print(f'passed {i}, id: {game_id}')\n",
    "        missed_games.append(game_id)\n",
    "        i += 1\n",
    "        pass\n",
    "\n",
    "\n",
    "print(f'DOING {len(missed_games)} MISSED GAMES')\n",
    "i=1\n",
    "missed_dfs = []\n",
    "for game_id in missed_games:\n",
    "    try: \n",
    "        time.sleep(.75) #prevent connection time-out\n",
    "        b = boxscoresummaryv2.BoxScoreSummaryV2(game_id=game_id, timeout = 100).get_data_frames()[4]\n",
    "        b['GAME_ID'] = game_id\n",
    "        missed_dfs.append(b)\n",
    "    except:\n",
    "        print(f'passed {i}, id: {game_id}')\n",
    "        missed_games.append(game_id)\n",
    "        i += 1\n",
    "        pass\n",
    "attendance_2019 = pd.concat(attendance_dfs)\n",
    "missed_games_2019 = pd.concat(missed_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ca4ab2-d109-4925-b053-f5b269546cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_2019 = pd.concat([attendance_2019, missed_games_2019])\n",
    "final_2019['GAME_DATE'] = pd.to_datetime(final_2019['GAME_DATE'])\n",
    "final_2019 = final_2019.sort_values('GAME_DATE')\n",
    "final_2019 = final_2019.merge(games_2019, how='left', on='GAME_ID')\n",
    "final_2019.to_csv('data/attendance_2019.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ac697e-ee95-4f6e-b09d-abc21281c8d1",
   "metadata": {},
   "source": [
    "#### 2018-2019 Season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6feeeed1-1916-4f73-ae3d-65b9ba805789",
   "metadata": {},
   "outputs": [],
   "source": [
    "games_2018 = game_data(2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1d0258-7399-4b6f-ae30-0e5919502f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "missed_games = []\n",
    "attendance_dfs = []\n",
    "\n",
    "i = 1\n",
    "for game_id in games_2018['GAME_ID']:\n",
    "    try: \n",
    "        time.sleep(.75) #prevent connection time-out\n",
    "        b = boxscoresummaryv2.BoxScoreSummaryV2(game_id=game_id, timeout = 100).get_data_frames()[4]\n",
    "        b['GAME_ID'] = game_id\n",
    "        attendance_dfs.append(b)\n",
    "    except:\n",
    "        print(f'passed {i}, id: {game_id}')\n",
    "        missed_games.append(game_id)\n",
    "        i += 1\n",
    "        pass\n",
    "\n",
    "\n",
    "print(f'DOING {len(missed_games)} MISSED GAMES')\n",
    "i=1\n",
    "missed_dfs = []\n",
    "for game_id in missed_games:\n",
    "    try: \n",
    "        time.sleep(.75) #prevent connection time-out\n",
    "        b = boxscoresummaryv2.BoxScoreSummaryV2(game_id=game_id, timeout = 100).get_data_frames()[4]\n",
    "        b['GAME_ID'] = game_id\n",
    "        missed_dfs.append(b)\n",
    "    except:\n",
    "        print(f'passed {i}, id: {game_id}')\n",
    "        missed_games.append(game_id)\n",
    "        i += 1\n",
    "        pass\n",
    "attendance_2018 = pd.concat(attendance_dfs)\n",
    "missed_games_2018 = pd.concat(missed_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d76e0b9-717b-45a6-b6bb-3ccaae5cb17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_2018 = pd.concat([attendance_2018, missed_games_2018])\n",
    "final_2018['GAME_DATE'] = pd.to_datetime(final_2018['GAME_DATE'])\n",
    "final_2018 = final_2018.sort_values('GAME_DATE')\n",
    "final_2018 = final_2018.merge(games_2018, how='left', on='GAME_ID')\n",
    "final_2018.to_csv('data/attendance_2018.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f968c57-d70e-4b03-a860-7aebc7e726c6",
   "metadata": {},
   "source": [
    "#### American Census Survey Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038fc0ad-552e-416e-ad99-52f78cc65db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in dataset containing arena city and FIPS code\n",
    "state_fips = pd.read_csv('data/state_fips.csv')\n",
    "state_fips['State'] = state_fips['State'].astype(str).str.zfill(2)\n",
    "state_fips['County'] = state_fips['County'].astype(str).str.zfill(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11f5c2f-e63a-4907-90f5-f832572bfcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to convert json output to dataframe for clean output\n",
    "def json_to_dataframe(response):\n",
    "    return pd.DataFrame(response.json()[1:], columns=col_names)\n",
    "\n",
    "census_years = ['2021','2020','2019']\n",
    "seasons = [2023,2022,2020]\n",
    "census_dfs = []\n",
    "for x in range(3):\n",
    "    for i in range(len(state_fips)):\n",
    "        base_url = f'http://api.census.gov/data/{census_years[x]}/acs/acs5'\n",
    "        # Specify Census variables and other predicates\n",
    "        get_vars = [\"NAME\",  # variable codes go here and below\n",
    "                    \"B01003_001E\", # total population\n",
    "                    \"B23025_002E\", # total pop in education data\n",
    "                    \"B23025_005E\", # total pop < high school education\n",
    "                    \"B06009_003E\", # Total pop high school graduate\n",
    "                    \"B06009_004E\", # Total pop w/ some college or associates\n",
    "                    \"B06009_005E\", # Total pop w/ bachelors\n",
    "                    \"B06009_006E\", # Total pop w/ grad degree\n",
    "                    \"B13002_001E\", # Total women 15 TO 50y who birthed in last 12m'\n",
    "                    'B19001_001E', # Total number of households in household income data'\n",
    "                    'B19001_002E', # household income bracket variables start here\n",
    "                    'B19001_003E',\n",
    "                    'B19001_004E',\n",
    "                    'B19001_005E',\n",
    "                    'B19001_006E',\n",
    "                    'B19001_007E',\n",
    "                    'B19001_008E', \n",
    "                    'B19001_009E',\n",
    "                    'B19001_010E',\n",
    "                    'B19001_011E',\n",
    "                    'B19001_012E',\n",
    "                    'B19001_013E',\n",
    "                    'B19001_014E',\n",
    "                    'B19001_015E',\n",
    "                    'B19001_016E',\n",
    "                    'B19001_017E',\n",
    "                    'B25064_001E', # median gross rent \n",
    "                    'B17001_001E', # total for poverty level\n",
    "                    'B17001_002E' # total under poverty level\n",
    "        ]\n",
    "        predicates = {}\n",
    "        predicates[\"get\"] = \",\".join(get_vars)\n",
    "        predicates[\"for\"] = f\"county:{str(state_fips.loc[i,'County'])}\" # select all tracts\n",
    "        predicates[\"in\"] = f\"state:{str(state_fips.loc[i,'State'])}\" # list the relevant states of interest (no space after commas)\n",
    "\n",
    "        # Execute the request, examine text of response object\n",
    "        r = requests.get(base_url, params=predicates)\n",
    "        col_names = ['Name', \n",
    "                 'Total Population',\n",
    "                 'Total labor force',\n",
    "                 'Total Unemployed',\n",
    "                 'Total pop high school graduate',\n",
    "                 'Total pop w/ some college or associates',\n",
    "                 'Total pop w/ bachelors',\n",
    "                 'Total pop w/ grad degree',\n",
    "                 'Total women 15 TO 50y who birthed in last 12m',\n",
    "                 'Total number of households in household income data',\n",
    "                 'Total with household income <$10k', # all household income data for past 12m\n",
    "                 'Total with household income $10-15k',\n",
    "                 'Total with household income $15-20k',\n",
    "                 'Total with household income $20-25k',\n",
    "                 'Total with household income $25-30k',\n",
    "                 'Total with household income $30-35k',\n",
    "                 'Total with household income $35-40k',\n",
    "                 'Total with household income $40-45k',\n",
    "                 'Total with household income $45-50k',\n",
    "                 'Total with household income $50-60k',\n",
    "                 'Total with household income $60-75k',\n",
    "                 'Total with household income $75-100k',\n",
    "                 'Total with household income $100-125k',\n",
    "                 'Total with household income $125-150k',\n",
    "                 'Total with household income $150-200k',\n",
    "                 'Total with household income $200k+',\n",
    "                 'Median gross rent',\n",
    "                 'Total for poverty level',\n",
    "                 'Total under poverty level',\n",
    "                 'state',\n",
    "                 'county']\n",
    "\n",
    "        df_census = json_to_dataframe(r)\n",
    "\n",
    "        for c in col_names: # set the columns from type string to type int\n",
    "          if c == \"state\" or \"county\" or \"tract\":\n",
    "            continue\n",
    "          if c != \"Name\":\n",
    "            df_census[c] = df_census[c].astype(float)\n",
    "\n",
    "        df_census['Season'] = seasons[x]\n",
    "        team = state_fips.loc[i,'Team Code']\n",
    "        df_census['Team'] = team\n",
    "        census_dfs.append(df_census)\n",
    "    print('finished season ' + str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704feb75-f45e-49c1-a4bd-926b3a243b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_census_df = pd.concat(census_dfs)\n",
    "final_census_df.reset_index(inplace = True, drop = True)\n",
    "final_census_df.to_csv('data/census_data.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
